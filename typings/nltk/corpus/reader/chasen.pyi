"""
This type stub file was generated by pyright.
"""

from nltk.corpus.reader.api import *
from nltk.corpus.reader.util import *

class ChasenCorpusReader(CorpusReader):
    def __init__(self, root, fileids, encoding=..., sent_splitter=...) -> None:
        ...

    def words(self, fileids=...): # -> str | ConcatenatedCorpusView | LazyConcatenation | list | tuple[()] | Element:
        ...

    def tagged_words(self, fileids=...): # -> str | ConcatenatedCorpusView | LazyConcatenation | list | tuple[()] | Element:
        ...

    def sents(self, fileids=...): # -> str | ConcatenatedCorpusView | LazyConcatenation | list | tuple[()] | Element:
        ...

    def tagged_sents(self, fileids=...): # -> str | ConcatenatedCorpusView | LazyConcatenation | list | tuple[()] | Element:
        ...

    def paras(self, fileids=...): # -> str | ConcatenatedCorpusView | LazyConcatenation | list | tuple[()] | Element:
        ...

    def tagged_paras(self, fileids=...): # -> str | ConcatenatedCorpusView | LazyConcatenation | list | tuple[()] | Element:
        ...



class ChasenCorpusView(StreamBackedCorpusView):
    """
    A specialized corpus view for ChasenReader. Similar to ``TaggedCorpusView``,
    but this'll use fixed sets of word and sentence tokenizer.
    """
    def __init__(self, corpus_file, encoding, tagged, group_by_sent, group_by_para, sent_splitter=...) -> None:
        ...

    def read_block(self, stream): # -> list:
        """Reads one paragraph at a time."""
        ...



def demo(): # -> None:
    ...

def test(): # -> None:
    ...

if __name__ == "__main__":
    ...
